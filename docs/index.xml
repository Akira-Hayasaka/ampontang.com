<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Akira Hayasaka</title>
    <link>https://akira-hayasaka.github.io/web/</link>
    <description>Recent content on Akira Hayasaka</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-JP</language>
    <lastBuildDate>Fri, 07 Jan 2022 14:32:23 +0900</lastBuildDate><atom:link href="https://akira-hayasaka.github.io/web/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>numpyroでベイズ線形回帰</title>
      <link>https://akira-hayasaka.github.io/web/posts/bayesian_linreg/</link>
      <pubDate>Fri, 07 Jan 2022 14:32:23 +0900</pubDate>
      
      <guid>https://akira-hayasaka.github.io/web/posts/bayesian_linreg/</guid>
      <description>線形回帰は全ての基本です。
変分推論のロジックがわかったら、エグい計算はライブラリを使って避けたいです。
model $$ \begin{align*} y_n &amp;amp; \in \mathbb{R} \qquad (output) \\ x_n &amp;amp; \in \mathbb{R}^M \quad e.g. (1,x,x^2,x^3) \qquad (input) \\ \textbf{w} &amp;amp; \in \mathbb{R}^M \qquad (parameter) \\ \epsilon_n &amp;amp; \in \mathbb{R} \qquad (noise) \end{align*} $$
$$ y_n = \textbf{w}^T\textbf{x}_n + \epsilon_n \\ \epsilon_n \sim Norm(\epsilon_n|0,\lambda^{-1}) $$
$$ p(\textbf{t},\textbf{w}|\textbf{x},\alpha^{-1},\beta^{-1}) = p(\textbf{w}|\alpha^{-1})\prod^{\textit{N}}_{n=1}p(\textit{t}_n|\textbf{w},\textit{x}_n,\beta^{-1}) $$
$$ = Norm(\textbf{w}|0,\alpha^{-1})\prod^{\textit{N}}_{n=1}Norm(t_n|\textbf{w}^T\phi(\textit{x}_n),\beta^{-1}) $$
scipy for modeling M = 3 def phi_basis_fn(x): result = [] result.append(1.0) for i in range(M-1): result.</description>
    </item>
    
    <item>
      <title>経験分布とは？</title>
      <link>https://akira-hayasaka.github.io/web/posts/empirical_dist/</link>
      <pubDate>Fri, 07 Jan 2022 12:59:05 +0900</pubDate>
      
      <guid>https://akira-hayasaka.github.io/web/posts/empirical_dist/</guid>
      <description>&amp;ldquo;The Dirac Distribution and Empirical Distribution&amp;rdquo; ↑ は、Goodfellow本 3.9.5節のタイトルです。Empirical Distribution が「経験分布」です。
経験分布はデータのサンプル（=観測・経験）集合の確率分布です。最尤推定はつまるところ、この経験分布と想定されるモデルの分布（正規分布、ベルヌーイ、カテゴリカルなど）の間のKLダイバージェンスを最小化するように訓練することです。そしてKLダイバージェンスを最小化するということは、交差エントロピーを最小化することと同じです。（この段でMSEは経験分布とガウス分布をモデルに仮定した場合の交差エントロピーだということがわかる）（ Goodfellow本 5.5節 あたりに書いてある)
何が言いたいかというと、経験分布とモデル分布の比較として最尤推定を捉えれば、回帰・2クラス分類・多クラス分類の”各種”誤差関数の根っこは同じになって、全部一貫して理解できるので、嬉しい、ということです。
そんな経験分布ですが、
 経験分布は、 ディラック分布を構成要素としていて、 それはディラックのデルタ関数により確率密度関数として定義される  なのですが、読んでるだけだとそもそも３のディラックのデルタ関数のピンが来ない。理解のためにこんな感じかという実装をしてみました。
サンプルが正規分布してるとして、
import jax.numpy as jnp from jax import random import numpyro.distributions as dist import matplotlib.pyplot as plt; key = random.PRNGKey(49) normal = dist.Normal(loc=0.5, scale=1.) samples = normal.sample(key, (1000,)) plt.hist(samples) plt.show() このサンプルを確率分布にしたものが、経験分布です。なので、
def dirac_delta_fn(xx, sigma): val = [] for x in xx: if -(1 / (2 * sigma)) &amp;lt;= x and x &amp;lt;= (1 / (2 * sigma)): val.</description>
    </item>
    
    <item>
      <title>Hello</title>
      <link>https://akira-hayasaka.github.io/web/posts/hello/</link>
      <pubDate>Sat, 01 Jan 2022 00:00:22 +0900</pubDate>
      
      <guid>https://akira-hayasaka.github.io/web/posts/hello/</guid>
      <description>備忘録、近況報告のために書きます。
技術的なことを話したり、デモを投稿したり、デジタル系施策・企画に何か話したりする思います。最近ずっと統計的推測・機械学習まわりをやっているので、その成長記録としても残していきます。</description>
    </item>
    
    <item>
      <title>about</title>
      <link>https://akira-hayasaka.github.io/web/about/</link>
      <pubDate>Wed, 06 Jan 2021 12:23:01 +0900</pubDate>
      
      <guid>https://akira-hayasaka.github.io/web/about/</guid>
      <description>Akira Hayasaka
freelance programmer / engineer / digital craft(manship).
アート文脈への技術応用をずっとやってきました。これからも頑張ります。
このブログは、備忘録、近況報告のために書きます。
技術的なことを話したり、デモを投稿したり、デジタル系施策・企画について何か話したりする思います。最近ずっと統計的推測・機械学習まわりをやっているので、その成長記録も残していきます。</description>
    </item>
    
    <item>
      <title>work</title>
      <link>https://akira-hayasaka.github.io/web/work/</link>
      <pubDate>Wed, 06 Jan 2021 12:23:01 +0900</pubDate>
      
      <guid>https://akira-hayasaka.github.io/web/work/</guid>
      <description>君も博士になれる展 https://lab-wakabadai.com/kimimohakase/
鴨川シーワールド ベルーガパフォーマンスシアター http://www.kamogawa-seaworld.jp/aquarium/program/beluga.html http://www.kids-event.jp/report/10603/
ベルーガが超音波で空間や物を認識している様子が見られる。 人間の可聴域をはるかに超えた、超音波による「エコロケーション（反響定位）」をリアルタイムにキャプチャ・ビジュアライズ（可視化）し、水槽上部のモニターに表示するシステムを制作。
日本科学未来館 Geo-Prism https://www.miraikan.jst.go.jp/exhibition/tsunagari/geo-prism.html
AR（拡張現実感）技術を用いて、ジオ･コスモスに地球海流や人工衛星データなどのシミュレーションを重ねて表示できるシステム。CGと複数のカメラからの映像をダイナミックに織りまぜたデータが、地球上に可視化される。多くの研究者やクリエイターが独自にコンテンツ開発に参加できるフレームワークアプリとして制作。
JR東京駅 Tokyo Colors https://www.youtube.com/watch?time_continue=1&amp;amp;v=EKVkBp_e7Cs
JR東京駅のコンコース（グランルーフ）に3100本のLED灯体を設置し、風向風速計により会場を通り抜ける風を検知し、敷き詰められたLEDによりリアルタイムに風向・風速のセンシングデータをビジュアライズ、同時にサウンドを生成する。風の体感を視覚・聴覚と共有するシステムを制作。
鴨川シーワールド Kurage Life https://www.kamogawa-seaworld.jp/facilities/area/kuragelife/
水族館の常設展示用に作成された、インタラクティブコンテンツ。手押しポンプで泡を膨らませるとクラゲの幼生が現れ、泡の中で成長・変態していく様子が観察できる。
鴨川シーワールド コーラルメッセージ https://www.kamogawa-seaworld.jp/facilities/area/coral/
水族館の常設展示用に作成された、インタラクティブコンテンツ。お客様がタッチパネル上に描いた魚を、大型スクリーンの「サンゴの海」の中に泳がせることで、水槽の魚を見るだけでは伝えきれない本物の“生態系”の営みを、楽しみながら学べる。</description>
    </item>
    
    <item>
      <title>テスト1</title>
      <link>https://akira-hayasaka.github.io/web/posts/test/</link>
      <pubDate>Wed, 06 Jan 2021 12:23:01 +0900</pubDate>
      
      <guid>https://akira-hayasaka.github.io/web/posts/test/</guid>
      <description>テスト tttsssttt
Headings blah
H1 blah
H6 blah
Paragraph blah
Tables    Name Age     Bob 27   Alice 23    Inline Markdown within tables    Italics Bold Code     italics bold code    Code Blocks Code block with backticks int main() { int y = SOME_MACRO_REFERENCE; int x = 5 + 6; cout &amp;lt;&amp;lt; &amp;#34;Hello World!</description>
    </item>
    
  </channel>
</rss>
